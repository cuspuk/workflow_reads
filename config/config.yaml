reads: # Specify the order and methods for each read processing step. If no method is specified, the step will not be performed.
  subsampling: null # null/enum: Subsampling method, if not set, subsampling will not be performed. Allowed: 'seqtk'.
  trimming: "cutadapt" # null/enum: Trimming method, if not set, trimming will not be performed. Allowed: 'cutadapt'.
  decontamination: "kraken" # null/enum: Decontamination method, if not set, decontamination will not be performed. Allowed: 'kraken'.
  deduplication: null # null/enum: Deduplication method, if not set, deduplication will not be performed. Allowed: 'fastuniq'.
  _generate_fastqc_for: ["original", "decontamination"] # list of enum: Specify which steps to generate fastqc for. Allowed: 'original','subsampling','trimming','decontamination','deduplication'.

# HYPERPARAMETERS

reads__subsampling__seqtk: # Relevant only if reads->subsampling is set to seqtk.
  seed: 1 # int(1): Seed value to use for random number generator.
  n_reads: TO_BE_DEFINED # int: Number of reads to subsample.
  reduce_memory: true # bool(true): Set to 2-pass mode, slower but with less memory used.

reads__trimming__cutadapt: # Relevant only if reads->trimming is set to cutadapt.
  cut_from_start_r1: null # null/int: Removes a specified number of bases from the beginning of the R1 read.
  cut_from_start_r2: null # null/int: Removes a specified number of bases from the beginning of the R2 read.
  cut_from_end_r1: null # null/int: Removes a specified number of bases from the end of the R1 read.
  cut_from_end_r2: null # null/int: Removes a specified number of bases from the end of the R2 read.
  quality_cutoff_from_3_end_r1: 20 # int(20): Removes lower quality bases from the 3' end of the R1 read.
  quality_cutoff_from_5_end_r1: 20 # int(20): Removes lower quality bases from the 5' end of the R1 read.
  quality_cutoff_from_3_end_r2: 20 # int(20): Removes lower quality bases from the 3' end of the R2 read.
  quality_cutoff_from_5_end_r2: 20 # int(20): Removes lower quality bases from the 5' end of the R2 read.
  nextseq_trimming_mode: false # bool(false): Modify quality-trimming algorithm to expect two-color chemistry data (NextSeq).
  do_adapter_removal: false # bool(false): Whether to do adapter removal or not.
  adapter_removal: # Relevant only if do_adapter_removal is set to true.
    action: "trim" # enum(trim): Defines an action to perform with the found adapter. Allowed: 'retain','trim','mask','none','lowercase'.
    overlap: 3 # int(3): Minimum number of bases required to overlap with the adapter.
    error_rate: 0.1 # float(0.1): Error tolerance used when searching for adapter.
    times: 1 # int(1): How many times to repeat adapter removal.
    keep_trimmed_only: false # bool(false): Discard reads with no adapters found.
    adapters_anywhere_file: TO_BE_DEFINED # null/str: Fasta file path with adapters to be matched 'anywhere'.
    adapters_3_end_file: TO_BE_DEFINED # null/str: Fasta file path with adapters to be matched at 3'end.
    adapters_5_end_file: TO_BE_DEFINED # null/str: Fasta file path with adapters to be matched at 5'end.
  shorten_to_length: null # null/int: Shorten each read to the specified length. Corresponds to the cutadapt length parameter.
  trim_N_bases_on_ends: false # bool(false): Set to true to trim 'N' bases on ends.
  min_length_r1: 45 # null/int: Discards R1 reads shorter than this. Recommended to set at least to 1, to discard empty reads.
  min_length_r2: 45 # null/int: Discards R2 reads shorter than this. Recommended to set at least to 1, to discard empty reads.
  max_length_r1: null # null/int: Discards R1 reads longer than this value.
  max_length_r2: null # null/int: Discards R2 reads longer than this value.
  max_n_bases: null # null/int: Removes reads with more 'N' bases than the specified number.
  max_expected_errors: null # null/int: Discard reads whose expected number of errors exceeds this value.

reads__decontamination__kraken: # Relevant only if reads->decontamination is set to kraken.
  kraken_dir: "/data/genome/metagenome/kraken/k2_pluspf_20240112" # str: Directory with the kraken DB files. If does not exist, the workflow tries to download DB by using the basename. See https://benlangmead.github.io/aws-indexes/k2.
  taxa_ids: [9606] # list of min 1 int([9606]): List of taxonomy IDs for filter logic. Example: 9606 - Homo Sapiens of rank=species.
  filter_mode: "exclude" # enum(exclude): Reads with specified taxa ids are either excluded or included. Allowed: 'include','exclude'.
  filter_children: false # bool(false): Filter reads classified at more specific levels than specified taxonomy ID levels.
  filter_ancestors: false # bool(false): Filter reads classified at all taxonomy levels between root and the specified taxonomy ID levels.
  save_memory: true # bool(true): If true, kraken limits RAM memory usage but sacrifices speed.
  generate_krona: false # bool(false): If true, krona is generated from kraken report.
  krona_dir: "/data/genome/taxonomy/krona/2023-12-03/" # null/str: Directory where krona dataset is located, or where will be downloaded.

reads__deduplication__fastuniq: {} # Relevant only if reads->deduplication is set to fastuniq. There are no parameters to be defined.

# RESOURCES

max_threads: 8 # int(8): Number of maximum threads to use in jobs.
max_mem_mb: 4096 # int(4096): Maximum memory in megabytes to allocate for any job.
resources:
  reads__trimming_mem_mb: 4096 # int(4096): Memory in MB to reserve for trimming.
  reads__fastqc_mem_mb: 2048 # int(2048): Memory in MB to reserve for fastqc.
threads:
  reads__trimming: 4 # int(4): Number of threads to use for trimming.
  reads__deduplication: 4 # int(4): Number of threads to use for deduplication.
  reads__decontamination: 8 # int(8): Number of threads to use for decontamination.
  reads__fastqc: 1 # int(1): Number of threads to use for fastqc.
